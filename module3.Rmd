---
title: "module3"
author: "GroupeB"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r importation-dataset}
df <- read.csv("College.csv")
head(df)
```

## Exercice 1 :

Pour chacune des parties (a) à (d), indiquez si nous nous attendons généralement à ce que les performances d’une méthode d’apprentissage statistique flexible soient meilleures ou pires que celles d’une méthode rigide. Justifiez votre réponse.

(a)- La taille de l’échantillon 
est extrêmement grande et le nombre de prédicteurs 
est petit.

**Rép** : Si on a beaucoup de données et peu de prédicteurs, c'est mieux d'opter pour une méthode rigide. Cela évitera 
de trop s'adapter aux donner et créer des problèmes de sur ajustement.

(b)- Le nombre de prédicteurs 
est extrêmement grand et le nombre d’observations 
est petit

**Rép** : La méthode rigide est encore mieux. En effet, avec peu d'observations, une méthode flexible a 
assez de lattitude pour s'ajuster à l'ensemble des observations et mal généraliser. 

(c)- La relation entre les prédicteurs et la réponse est fortement non linéaire.

**Rép** (je ne sais pas)

(d)-La variance des termes d’erreur, c’est-à-dire 
, est extrêmement élevé

**Rép** : 


## Exercice 2 :

Expliquez si chaque scénario est un problème de classification ou de régression, et indiquez si nous sommes plus intéressés par l’inférence ou la prédiction. 


(a)-Nous collectons un ensemble de données sur les 500 plus grandes entreprises aux États-Unis. Pour chaque entreprise, nous enregistrons les bénéfices, le nombre d’employés, le secteur d’activité et le salaire du PDG. Nous souhaitons comprendre quels facteurs affectent le salaire du PDG.

**Rep**: C'est un problème de **regression**, par ce que le salaire est quantitatif continue.
On veut faire une **inférence**. par ce que ce n'est pas le salaire en soi qui nous interesse, mais les variables qui le
déterminent.

(b)-Nous envisageons de lancer un nouveau produit et souhaitons savoir si ce sera un succès ou un échec. Nous collectons des données sur 20 produits similaires précédemment lancés. Pour chaque produit, nous avons enregistré s’il s’agissait d’un succès ou d’un échec, le prix facturé pour le produit, le budget marketing, le prix de la concurrence et dix autres variables.

**Rép**: C'est  un problème de **classification** (Succès ou échec), on veut faire une **prédiction**

(c)- Nous souhaitons prédire la variation en % du taux de change USD/euro par rapport aux variations hebdomadaires des marchés boursiers mondiaux. C’est pourquoi nous collectons des données hebdomadaires pour toute l’année 2012. Pour chaque semaine, nous enregistrons le % de variation de la parité USD/Euro, le % de variation du marché américain, le % de variation du marché britannique et le % de variation du marché allemand.

**Rép**: problème de **regression**, on veut faire une **prédiction**

### Exercice 3

```{r}
df <- data.frame(
  X1 = c(0, 2, 0, 0, -1, 1),
  X2 = c(3, 0, 1, 1, 0, 1),
  X3 = c(0, 0, 3, 2, 1, 1),
  Y = c("Rouge", "Rouge", "Rouge", "Vert", "Vert", "Rouge")
)
print(df)
```

#a-Calculons la distance euclidienne entre chaque observation et le point de test

on sait que X1=X2=X3=0 donc le point de test (0,0,0). 

On sait que la distance euclidienne entre deux observationsest: distance <- sqrt(sum((x - y)^2))


```{r}
test <- c(0, 0, 0)
distances <- sqrt(rowSums((df[, 1:3] - test)^2))
df$Distance <- distances
print(df)
```
b-Quelle est notre prédiction avec K=1 Pourquoi?

#Pour K=1  la prédiction est  vert

Car le point le plus proche de 1 est la distance de l'observation 5 de coordonner (−1,0,1)  qui de 1.41  et de couleur vert.

c-Quelle est notre prédiction avec K=3 Pourquoi?

#Pour K=3  La prediction est  Rouge 

Car les 3 points les plus proches sont les observations 5, 6 et 2 avec des distances respectives
Observation 5 (−1,0,1) distance 1.41 de couleur  Vert
Observation 6 (1,1,1) distance 1.73 de couleur Rouge
Observation 2 (2,0,0) distance 2 de couleur Rouge 
et la couleur dominante est Rouge

d-Si la règle de décision de Bayes dans ce problème est hautement non linéaire, alors nous attendrions-nous à ce que la meilleure valeur pour soit grande ou petite ? Pourquoi?

Si la règle de décision de Bayes est hautement non linéaire, une petite valeur de k est préférable car Cela permet de mieux capturer les variations locales et les plus  frontières complexes.

### Exercice 4 
Je l'ai fait sur feuille comment l'ajouter sur R aucune idée 

### Exercice 5 

### Exercice 6

### Exercice 7 

### Exercice 8

### Pratique


